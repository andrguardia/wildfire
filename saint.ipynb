{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "989ac1c3",
   "metadata": {},
   "source": [
    "# SAINT Transformer Architecture for wildfire prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bf8584",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "In this section we will install all the dependencies needed to run the code, load the dataset, and import all the necessary libraries required to run the SAINT transformer architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c96a3174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no such file or directory: 2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "%pip install --upgrade torch pytorch_lightning scikit-learn pandas numpy<2 matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bc4200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1129582c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  system:index  EVH   EVT    NDVI  PRES_max  SPFH_max    TMP_max  WIND_max  \\\n",
      "0        0_0_0   75  3092  5691.0   97165.0  0.006520  17.850000      4.88   \n",
      "1        0_1_0   89  3900  6176.0   98114.0  0.006578  21.589990      4.59   \n",
      "2        0_2_0   96  3097  6563.0   97881.0  0.007021  19.989984      3.85   \n",
      "3        0_3_0   21  3296  4034.0   98933.0  0.006326  22.369989      4.08   \n",
      "4        0_4_0   99  3097  8027.0   97243.0  0.007369  16.290002      5.66   \n",
      "\n",
      "   burned        date  elevation  sm_profile  sm_profile_wetness  sm_rootzone  \\\n",
      "0       0  2023-04-01  348.75693    0.365752            0.797881     0.389533   \n",
      "1       0  2023-04-01  363.53400    0.356276            0.777190     0.380164   \n",
      "2       0  2023-04-01  409.15347    0.361830            0.789306     0.381324   \n",
      "3       0  2023-04-01  263.18298    0.358382            0.781829     0.382392   \n",
      "4       0  2023-04-01  323.89856    0.367979            0.802734     0.387794   \n",
      "\n",
      "   sm_rootzone_wetness  sm_surface  sm_surface_wetness  \\\n",
      "0             0.849741    0.349155            0.761735   \n",
      "1             0.829294    0.351032            0.765764   \n",
      "2             0.831857    0.352863            0.769822   \n",
      "3             0.834207    0.354602            0.773576   \n",
      "4             0.845987    0.356098            0.776841   \n",
      "\n",
      "                                                .geo  \n",
      "0  {\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...  \n",
      "1  {\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...  \n",
      "2  {\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...  \n",
      "3  {\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...  \n",
      "4  {\"geodesic\":false,\"type\":\"Point\",\"coordinates\"...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37e96cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Handle missing values\n",
    "df.ffill(inplace=True)\n",
    "\n",
    "# Clean up column names (remove leading/trailing spaces)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Encode categorical features\n",
    "cat_cols = ['EVT']\n",
    "\n",
    "# Encode numerical features\n",
    "num_cols = [\n",
    "    'EVH', 'NDVI', 'PRES_max', 'SPFH_max', 'TMP_max', 'WIND_max',\n",
    "    'elevation', 'sm_profile', 'sm_profile_wetness', 'sm_rootzone',\n",
    "    'sm_rootzone_wetness', 'sm_surface', 'sm_surface_wetness'\n",
    "]\n",
    "\n",
    "# Check and process 'date' column\n",
    "if 'date' in df.columns:\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "    num_cols += ['year', 'month', 'day']\n",
    "    df.drop(columns=['date'], inplace=True)\n",
    "\n",
    "# Ensure 'burned' is integer\n",
    "df['burned'] = df['burned'].astype(int)\n",
    "\n",
    "# Extract longitude and latitude from '.geo' JSON string\n",
    "def extract_coords(geo_str):\n",
    "    geo = json.loads(geo_str)\n",
    "    return pd.Series(geo['coordinates'], index=['longitude', 'latitude'])\n",
    "\n",
    "if '.geo' in df.columns:\n",
    "    df[['longitude', 'latitude']] = df['.geo'].apply(extract_coords)\n",
    "    num_cols += ['longitude', 'latitude']\n",
    "    df.drop(columns=['.geo'], inplace=True)\n",
    "\n",
    "target = 'burned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5345049a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system:index</th>\n",
       "      <th>EVH</th>\n",
       "      <th>EVT</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>PRES_max</th>\n",
       "      <th>SPFH_max</th>\n",
       "      <th>TMP_max</th>\n",
       "      <th>WIND_max</th>\n",
       "      <th>burned</th>\n",
       "      <th>elevation</th>\n",
       "      <th>...</th>\n",
       "      <th>sm_profile_wetness</th>\n",
       "      <th>sm_rootzone</th>\n",
       "      <th>sm_rootzone_wetness</th>\n",
       "      <th>sm_surface</th>\n",
       "      <th>sm_surface_wetness</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0_0</td>\n",
       "      <td>75</td>\n",
       "      <td>3092</td>\n",
       "      <td>5691.0</td>\n",
       "      <td>97165.0</td>\n",
       "      <td>0.006520</td>\n",
       "      <td>17.850000</td>\n",
       "      <td>4.88</td>\n",
       "      <td>0</td>\n",
       "      <td>348.75693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797881</td>\n",
       "      <td>0.389533</td>\n",
       "      <td>0.849741</td>\n",
       "      <td>0.349155</td>\n",
       "      <td>0.761735</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-118.815671</td>\n",
       "      <td>34.230304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_1_0</td>\n",
       "      <td>89</td>\n",
       "      <td>3900</td>\n",
       "      <td>6176.0</td>\n",
       "      <td>98114.0</td>\n",
       "      <td>0.006578</td>\n",
       "      <td>21.589990</td>\n",
       "      <td>4.59</td>\n",
       "      <td>0</td>\n",
       "      <td>363.53400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777190</td>\n",
       "      <td>0.380164</td>\n",
       "      <td>0.829294</td>\n",
       "      <td>0.351032</td>\n",
       "      <td>0.765764</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-118.546176</td>\n",
       "      <td>34.140472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_2_0</td>\n",
       "      <td>96</td>\n",
       "      <td>3097</td>\n",
       "      <td>6563.0</td>\n",
       "      <td>97881.0</td>\n",
       "      <td>0.007021</td>\n",
       "      <td>19.989984</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0</td>\n",
       "      <td>409.15347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.789306</td>\n",
       "      <td>0.381324</td>\n",
       "      <td>0.831857</td>\n",
       "      <td>0.352863</td>\n",
       "      <td>0.769822</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-118.582109</td>\n",
       "      <td>34.122506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_3_0</td>\n",
       "      <td>21</td>\n",
       "      <td>3296</td>\n",
       "      <td>4034.0</td>\n",
       "      <td>98933.0</td>\n",
       "      <td>0.006326</td>\n",
       "      <td>22.369989</td>\n",
       "      <td>4.08</td>\n",
       "      <td>0</td>\n",
       "      <td>263.18298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.781829</td>\n",
       "      <td>0.382392</td>\n",
       "      <td>0.834207</td>\n",
       "      <td>0.354602</td>\n",
       "      <td>0.773576</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-118.627025</td>\n",
       "      <td>34.176405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_4_0</td>\n",
       "      <td>99</td>\n",
       "      <td>3097</td>\n",
       "      <td>8027.0</td>\n",
       "      <td>97243.0</td>\n",
       "      <td>0.007369</td>\n",
       "      <td>16.290002</td>\n",
       "      <td>5.66</td>\n",
       "      <td>0</td>\n",
       "      <td>323.89856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.802734</td>\n",
       "      <td>0.387794</td>\n",
       "      <td>0.845987</td>\n",
       "      <td>0.356098</td>\n",
       "      <td>0.776841</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-118.707873</td>\n",
       "      <td>34.059624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  system:index  EVH   EVT    NDVI  PRES_max  SPFH_max    TMP_max  WIND_max  \\\n",
       "0        0_0_0   75  3092  5691.0   97165.0  0.006520  17.850000      4.88   \n",
       "1        0_1_0   89  3900  6176.0   98114.0  0.006578  21.589990      4.59   \n",
       "2        0_2_0   96  3097  6563.0   97881.0  0.007021  19.989984      3.85   \n",
       "3        0_3_0   21  3296  4034.0   98933.0  0.006326  22.369989      4.08   \n",
       "4        0_4_0   99  3097  8027.0   97243.0  0.007369  16.290002      5.66   \n",
       "\n",
       "   burned  elevation  ...  sm_profile_wetness  sm_rootzone  \\\n",
       "0       0  348.75693  ...            0.797881     0.389533   \n",
       "1       0  363.53400  ...            0.777190     0.380164   \n",
       "2       0  409.15347  ...            0.789306     0.381324   \n",
       "3       0  263.18298  ...            0.781829     0.382392   \n",
       "4       0  323.89856  ...            0.802734     0.387794   \n",
       "\n",
       "   sm_rootzone_wetness  sm_surface  sm_surface_wetness  year  month  day  \\\n",
       "0             0.849741    0.349155            0.761735  2023      4    1   \n",
       "1             0.829294    0.351032            0.765764  2023      4    1   \n",
       "2             0.831857    0.352863            0.769822  2023      4    1   \n",
       "3             0.834207    0.354602            0.773576  2023      4    1   \n",
       "4             0.845987    0.356098            0.776841  2023      4    1   \n",
       "\n",
       "    longitude   latitude  \n",
       "0 -118.815671  34.230304  \n",
       "1 -118.546176  34.140472  \n",
       "2 -118.582109  34.122506  \n",
       "3 -118.627025  34.176405  \n",
       "4 -118.707873  34.059624  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c59e8b",
   "metadata": {},
   "source": [
    "## üîß Defining the SAINT Model Architecture\n",
    "\n",
    "We build a **Transformer model** that works on tabular data:\n",
    "\n",
    "- **Categorical features** are turned into embeddings (like word vectors).\n",
    "- **Numerical features** are projected into the same embedding space via a linear layer.\n",
    "- All features become **tokens** and go into a Transformer Encoder.\n",
    "\n",
    "### Inside the Transformer:\n",
    "\n",
    "- **Self-Attention (column-wise)**: learns relationships between features.\n",
    "- **Intersample Attention (row-wise)**: each row can attend to other rows in the batch ‚Äî **unique to SAINT**.\n",
    "\n",
    "### Output Layer\n",
    "\n",
    "The transformer output goes through a simple classifier:\n",
    "\n",
    "- `Linear ‚Üí ReLU ‚Üí Dropout ‚Üí Linear ‚Üí Sigmoid (via BCEWithLogitsLoss)`\n",
    "\n",
    "### Class Imbalance Handling\n",
    "\n",
    "We use `BCEWithLogitsLoss` with a `pos_weight` parameter to account for the fact that wildfire events are **rare** in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b23083b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class SAINT(pl.LightningModule):\n",
    "    def __init__(self, num_cont, cat_dims=[], embed_dim=32, \n",
    "                 num_heads=4, num_layers=3, dropout=0.1, pos_weight=None, lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['pos_weight'])\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(dim, embed_dim) for dim in cat_dims\n",
    "        ])\n",
    "        self.cont_proj = nn.Linear(num_cont, embed_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim, nhead=num_heads, dropout=dropout,\n",
    "            batch_first=True, dim_feedforward=embed_dim*4\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "        if pos_weight is not None:\n",
    "            self.loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        else:\n",
    "            self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        tokens = []\n",
    "        for i, emb in enumerate(self.embeddings):\n",
    "            tokens.append(emb(x_cat[:, i]))\n",
    "        tokens.append(self.cont_proj(x_cont))\n",
    "        tokens = torch.stack(tokens, dim=1)\n",
    "        attn_output = self.transformer(tokens)\n",
    "        cls_token = attn_output.mean(dim=1)\n",
    "        return self.classifier(cls_token).squeeze(-1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_cat, x_cont, y = batch\n",
    "        logits = self(x_cat, x_cont)\n",
    "        loss = self.loss_fn(logits, y.float())\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_cat, x_cont, y = batch\n",
    "        logits = self(x_cat, x_cont)\n",
    "        loss = self.loss_fn(logits, y.float())\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.hparams.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23174917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class FireDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, X_train, y_train, X_test, y_test, cat_cols, batch_size=64):\n",
    "        super().__init__()\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.cat_cols = list(cat_cols)\n",
    "        self.batch_size = batch_size\n",
    "        self.device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Defensive: ensure all column names are strings\n",
    "        self.cat_cols = [str(col) for col in list(self.cat_cols)]\n",
    "        self.X_train.columns = [str(col) for col in self.X_train.columns]\n",
    "        self.X_test.columns = [str(col) for col in self.X_test.columns]\n",
    "        cat_cols = self.cat_cols\n",
    "        cont_cols = [col for col in self.X_train.columns if col not in cat_cols]\n",
    "\n",
    "        print(\"DEBUG cat_cols:\", cat_cols)\n",
    "        print(\"DEBUG cont_cols:\", cont_cols)\n",
    "        print(\"DEBUG X_train columns:\", self.X_train.columns)\n",
    "        print(\"DEBUG X_train[cat_cols] dtype:\", self.X_train[cat_cols].values.dtype)\n",
    "\n",
    "        X_train_cat = torch.tensor(self.X_train[cat_cols].values, dtype=torch.long, device=self.device)\n",
    "        X_train_cont = torch.tensor(self.X_train[cont_cols].values, dtype=torch.float32, device=self.device)\n",
    "        y_train = torch.tensor(self.y_train.values, dtype=torch.float32, device=self.device)\n",
    "        X_test_cat = torch.tensor(self.X_test[cat_cols].values, dtype=torch.long, device=self.device)\n",
    "        X_test_cont = torch.tensor(self.X_test[cont_cols].values, dtype=torch.float32, device=self.device)\n",
    "        y_test = torch.tensor(self.y_test.values, dtype=torch.float32, device=self.device)\n",
    "\n",
    "        self.train_dataset = TensorDataset(X_train_cat, X_train_cont, y_train)\n",
    "        self.val_dataset = TensorDataset(X_test_cat, X_test_cont, y_test)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26202c4",
   "metadata": {},
   "source": [
    "## Model Training with all features\n",
    "\n",
    "We use the SAINT architecture and Dataloader class to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90f07050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cat_cols = list(cat_cols)\n",
    "num_cols = list(num_cols)\n",
    "\n",
    "# Encode categorical columns\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "    df[col] = df[col].astype(int)  # Ensure integer type for embeddings\n",
    "\n",
    "# Compute cat_dims after encoding\n",
    "cat_dims = [df[col].nunique() for col in cat_cols]\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "\n",
    "X = df[cat_cols + num_cols]\n",
    "y = df['burned']\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Ensure categorical columns are first and in the same order as cat_cols\n",
    "all_cols = cat_cols + [col for col in X_train.columns if col not in cat_cols]\n",
    "X_train = X_train[all_cols]\n",
    "X_test = X_test[all_cols]\n",
    "\n",
    "# Double-check for out-of-range values in categorical columns\n",
    "for i, col in enumerate(cat_cols):\n",
    "    max_val = X_train[col].max()\n",
    "    assert max_val < cat_dims[i], f\"Column {col} has value {max_val} >= {cat_dims[i]}\"\n",
    "\n",
    "# Convert ONLY numerical columns to float32 for PyTorch compatibility\n",
    "for col in num_cols:\n",
    "    X_train[col] = X_train[col].astype(np.float32)\n",
    "    X_test[col] = X_test[col].astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec31e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Initialize model\n",
    "model = SAINT(\n",
    "    num_cont=len([col for col in X_train.columns if col not in cat_cols]),\n",
    "    cat_dims=cat_dims,\n",
    "    embed_dim=32,\n",
    "    num_heads=4,\n",
    "    num_layers=3\n",
    ")\n",
    "\n",
    "# Initialize DataModule\n",
    "dm = FireDataModule(X_train, y_train, X_test, y_test, cat_cols=cat_cols, batch_size=64)\n",
    "\n",
    "# Train with PyTorch Lightning using MPS (Mac GPU)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    accelerator='auto',  # This will use your Mac GPU!\n",
    "    devices=1,\n",
    "    callbacks=[\n",
    "        pl.callbacks.EarlyStopping(monitor='val_loss', patience=5),\n",
    "        pl.callbacks.ModelCheckpoint(monitor='val_loss', mode='min')\n",
    "    ]\n",
    ")\n",
    "\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c41dab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DataModule\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "model = SAINT(\n",
    "    num_cont=len([col for col in X_train.columns if col not in cat_cols]),\n",
    "    cat_dims=cat_dims,\n",
    "    embed_dim=32,\n",
    "    num_heads=4,\n",
    "    num_layers=3\n",
    ")\n",
    "\n",
    "# Initialize DataModule\n",
    "dm = FireDataModule(X_train, y_train, X_test, y_test, cat_cols=cat_cols, batch_size=64)\n",
    "\n",
    "dm = FireDataModule(X_train, y_train, X_test, y_test, cat_cols=cat_cols, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc5ee342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAINT(\n",
       "  (embeddings): ModuleList(\n",
       "    (0): Embedding(39, 32)\n",
       "  )\n",
       "  (cont_proj): Linear(in_features=13, out_features=32, bias=True)\n",
       "  (transformer): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       "  (loss_fn): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-instantiate and load the model\n",
    "model = SAINT.load_from_checkpoint(\n",
    "    '/Users/andrguardia/Documents/GitHub/wildfire/lightning_logs/version_14/checkpoints/epoch=20-step=191898.ckpt',\n",
    "    num_cont=13,\n",
    "    cat_dims=[39],\n",
    "    embed_dim=32,\n",
    "    num_heads=4,\n",
    "    num_layers=3,\n",
    "    dropout=0.1,\n",
    "    lr=0.001\n",
    ")\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8c84e137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG cat_cols: ['EVT']\n",
      "DEBUG cont_cols: ['EVH', 'NDVI', 'PRES_max', 'SPFH_max', 'TMP_max', 'WIND_max', 'elevation', 'sm_profile', 'sm_profile_wetness', 'sm_rootzone', 'sm_rootzone_wetness', 'sm_surface', 'sm_surface_wetness', 'year', 'month', 'day', 'longitude', 'latitude']\n",
      "DEBUG X_train columns: Index(['EVT', 'EVH', 'NDVI', 'PRES_max', 'SPFH_max', 'TMP_max', 'WIND_max',\n",
      "       'elevation', 'sm_profile', 'sm_profile_wetness', 'sm_rootzone',\n",
      "       'sm_rootzone_wetness', 'sm_surface', 'sm_surface_wetness', 'year',\n",
      "       'month', 'day', 'longitude', 'latitude'],\n",
      "      dtype='object')\n",
      "DEBUG X_train[cat_cols] dtype: int64\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "linear(): input and weight.T shapes cannot be multiplied (64x18 and 13x32)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m x_cont = x_cont.to(device)\n\u001b[32m     20\u001b[39m y_true = y_true.to(device)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_cont\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m probs = torch.sigmoid(logits)\n\u001b[32m     23\u001b[39m preds = (probs > \u001b[32m0.3\u001b[39m).long()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mSAINT.forward\u001b[39m\u001b[34m(self, x_cat, x_cont)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, emb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.embeddings):\n\u001b[32m     34\u001b[39m     tokens.append(emb(x_cat[:, i]))\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m tokens.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcont_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_cont\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     36\u001b[39m tokens = torch.stack(tokens, dim=\u001b[32m1\u001b[39m)\n\u001b[32m     37\u001b[39m attn_output = \u001b[38;5;28mself\u001b[39m.transformer(tokens)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: linear(): input and weight.T shapes cannot be multiplied (64x18 and 13x32)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Make sure your DataModule is set up\n",
    "dm.setup()\n",
    "val_loader = dm.val_dataloader()\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_cat, x_cont, y_true in val_loader:\n",
    "        x_cat = x_cat.to(device)\n",
    "        x_cont = x_cont.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        logits = model(x_cat, x_cont)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs > 0.3).long()\n",
    "        all_preds.extend(preds.cpu().detach().tolist())\n",
    "        all_labels.extend(y_true.cpu().detach().tolist())\n",
    "\n",
    "all_preds = np.array(all_preds).flatten()\n",
    "all_labels = np.array(all_labels).flatten()\n",
    "\n",
    "# Now you can compute metrics as before\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "f1 = f1_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds)\n",
    "recall = recall_score(all_labels, all_preds)\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea74cc42",
   "metadata": {},
   "source": [
    "### improving f1 score\n",
    "\n",
    "We will extract the importance scores of each feature here in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61d9c696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                feature  importance\n",
      "2                  NDVI    0.003059\n",
      "4              SPFH_max    0.001431\n",
      "9    sm_profile_wetness    0.001384\n",
      "1                   EVH    0.001271\n",
      "10          sm_rootzone    0.000810\n",
      "5               TMP_max    0.000720\n",
      "8            sm_profile    0.000679\n",
      "11  sm_rootzone_wetness    0.000573\n",
      "0                   EVT    0.000561\n",
      "7             elevation    0.000442\n",
      "6              WIND_max    0.000272\n",
      "12           sm_surface    0.000269\n",
      "13   sm_surface_wetness    0.000249\n",
      "3              PRES_max    0.000220\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train quick RF model to assess feature importance\n",
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "result = permutation_importance(rf, X_test, y_test, n_repeats=5, random_state=42)\n",
    "\n",
    "# Rank features\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': result.importances_mean\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b039521a",
   "metadata": {},
   "source": [
    "#### Feature Importance Analysis & Pruning Strategy\n",
    "\n",
    "üß† Observations from Permutation Importance\n",
    "\n",
    "Rank\tFeature\tImportance\tNotes\n",
    "- 1\tNDVI\t0.00306\t‚úÖ Strong vegetation signal ‚Äî keep\n",
    "\n",
    "- 2\tSPFH_max\t0.00143\t‚úÖ Specific humidity ‚Äî keep\n",
    "\n",
    "- 3\tsm_profile_wetness\t0.00138\t‚úÖ Soil moisture ‚Äî keep\n",
    "\n",
    "- 4\tEVH\t0.00127\t‚úÖ Likely vegetation height or evapotranspiration ‚Äî keep\n",
    "\n",
    "- 5‚Äì8\tsm_* features\t0.0006‚Äì0.0008\t‚ö†Ô∏è Redundant ‚Äî keep only top 1‚Äì2\n",
    "\n",
    "- 9\tEVT (categorical)\t0.00056\t‚úÖ Low score but keep ‚Äî embeddings may help\n",
    "\n",
    "- 10‚Äì13\televation, WIND_max, sm_surface, sm_surface_wetness, PRES_max\t‚â§ 0.0004\t‚ùå Very low signal ‚Äî drop candidates\n",
    "\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "‚úÖ Recommended Feature Selection\n",
    "\n",
    "Keep:\n",
    "\n",
    "selected_features = [\n",
    "    'NDVI', 'SPFH_max', 'sm_profile_wetness', 'EVH',  # top 4\n",
    "    'sm_rootzone',                                   # optional (moderate importance)\n",
    "    'EVT'                                            # categorical\n",
    "]\n",
    "\n",
    "Drop (low importance):\n",
    "\n",
    "drop_features = [\n",
    "    'PRES_max', 'WIND_max', 'elevation',\n",
    "    'sm_surface', 'sm_surface_wetness',\n",
    "    'sm_rootzone_wetness', 'sm_profile',\n",
    "    # optionally: 'TMP_max'\n",
    "]\n",
    "\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "üß™ Next Steps\n",
    "\t‚Ä¢\tRetrain SAINT with the pruned feature set.\n",
    "\t‚Ä¢\tEvaluate changes in F1 score, recall, and precision.\n",
    "\t‚Ä¢\tIterate: remove 1‚Äì2 additional features if no gain observed.\n",
    "\n",
    "If F1 or recall improves even slightly, you‚Äôve successfully reduced noise and improved generalization.\n",
    "\n",
    "Let me know if you want the updated preprocessing code with this pruning applied!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e7268f",
   "metadata": {},
   "source": [
    "## Model Training with pruned features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18a2d6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# === Feature Selection ===\n",
    "\n",
    "# Categorical features (keep EVT)\n",
    "cat_cols = ['EVT']\n",
    "\n",
    "# Numerical features (keep only the most important)\n",
    "num_cols = [\n",
    "    'NDVI',                # top 1\n",
    "    'SPFH_max',            # top 2\n",
    "    'sm_profile_wetness',  # top 3\n",
    "    'EVH',                 # top 4\n",
    "    'sm_rootzone',         # moderate importance\n",
    "    'TMP_max',             # top 5\n",
    "]\n",
    "\n",
    "\n",
    "# === Encode categorical columns ===\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "    df[col] = df[col].astype(int)  # Ensure integer type for embeddings\n",
    "\n",
    "# Compute cat_dims after encoding\n",
    "cat_dims = [df[col].nunique() for col in cat_cols]\n",
    "\n",
    "# === Scale numerical features ===\n",
    "scaler = StandardScaler()\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "\n",
    "# === Prepare Data ===\n",
    "X = df[cat_cols + num_cols]\n",
    "y = df['burned']\n",
    "\n",
    "# === Train/Test Split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Ensure categorical columns are first and in the same order as cat_cols\n",
    "all_cols = cat_cols + [col for col in X_train.columns if col not in cat_cols]\n",
    "X_train = X_train[all_cols]\n",
    "X_test = X_test[all_cols]\n",
    "\n",
    "# Double-check for out-of-range values in categorical columns\n",
    "for i, col in enumerate(cat_cols):\n",
    "    max_val = X_train[col].max()\n",
    "    assert max_val < cat_dims[i], f\"Column {col} has value {max_val} >= {cat_dims[i]}\"\n",
    "\n",
    "# Convert ONLY numerical columns to float32 for PyTorch compatibility\n",
    "for col in num_cols:\n",
    "    X_train[col] = X_train[col].astype(np.float32)\n",
    "    X_test[col] = X_test[col].astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7604f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG cat_cols: ['EVT']\n",
      "DEBUG cont_cols: ['NDVI', 'SPFH_max', 'sm_profile_wetness', 'EVH', 'sm_rootzone', 'TMP_max']\n",
      "DEBUG X_train columns: Index(['EVT', 'NDVI', 'SPFH_max', 'sm_profile_wetness', 'EVH', 'sm_rootzone',\n",
      "       'TMP_max'],\n",
      "      dtype='object')\n",
      "DEBUG X_train[cat_cols] dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name        | Type               | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | embeddings  | ModuleList         | 1.2 K  | train\n",
      "1 | cont_proj   | Linear             | 224    | train\n",
      "2 | transformer | TransformerEncoder | 38.1 K | train\n",
      "3 | classifier  | Sequential         | 1.1 K  | train\n",
      "4 | loss_fn     | BCEWithLogitsLoss  | 0      | train\n",
      "-----------------------------------------------------------\n",
      "40.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "40.7 K    Total params\n",
      "0.163     Total estimated model params size (MB)\n",
      "41        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56308abd8eed4a79984c34fe90fe1d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/usr/local/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f028dedd116d4c75b1ed31de297e10d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e21a5ca92b2c451da014eae378d781f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a3124a55384ba7941735f50e77b2a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71edb81be97d40d7a3b3573133227128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbbcd0e4f5fe4013b74bb8da8a3a26d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d73be11eca442249bb030256eac83b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ecd187f767445ea0febc8dffa676c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2647a58ff9124349b2a2c625f434cfc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5e45eb9d494702945e6c7b5742db25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac858ad4583447eb8d27d506a8b51a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e284959c9e431aa1c74bb9bf1c0c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdecebe4a27d4d0c950eefe89949d5a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "981f3f8ae53d4a37b5fe373c57b35a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a337c167b9c04f96a017b34dacb7fd46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b2b2d91c0c4ca793f3ba76f15c77f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e510da285a4e5fa63b1c8844409621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7806a131945c4b3c975d1a9df60c4607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9178f36efb484a8a7e3b1a5d614659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a3e2d5c7d5482da1fdfa83d8606f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122d6895da194ff2b10ccfc5f4b7fcc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6398dba6300d4829b3c48946e4368fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d99db60a867465895c1b512d3adea47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ae73c4e8b246a7bdf183d2d66b0f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f2fc3fef3f4fda8ad42b6f75f427b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Initialize model\n",
    "model = SAINT(\n",
    "    num_cont=len([col for col in X_train.columns if col not in cat_cols]),\n",
    "    cat_dims=cat_dims,\n",
    "    embed_dim=32,\n",
    "    num_heads=4,\n",
    "    num_layers=3\n",
    ")\n",
    "\n",
    "# Initialize DataModule\n",
    "dm = FireDataModule(X_train, y_train, X_test, y_test, cat_cols=cat_cols, batch_size=64)\n",
    "\n",
    "# Train with PyTorch Lightning using MPS (Mac GPU)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    accelerator='auto',  # This will use your Mac GPU!\n",
    "    devices=1,\n",
    "    callbacks=[\n",
    "        pl.callbacks.EarlyStopping(monitor='val_loss', patience=5),\n",
    "        pl.callbacks.ModelCheckpoint(monitor='val_loss', mode='min')\n",
    "    ]\n",
    ")\n",
    "\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0aa88011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAINT(\n",
       "  (embeddings): ModuleList(\n",
       "    (0): Embedding(39, 32)\n",
       "  )\n",
       "  (cont_proj): Linear(in_features=6, out_features=32, bias=True)\n",
       "  (transformer): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       "  (loss_fn): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-instantiate and load the model\n",
    "model = SAINT.load_from_checkpoint(\n",
    "    '/Users/andrguardia/Documents/GitHub/wildfire/lightning_logs/version_16/checkpoints/epoch=17-step=164484.ckpt'\n",
    ")\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aeaba9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG cat_cols: ['EVT']\n",
      "DEBUG cont_cols: ['EVH', 'NDVI', 'PRES_max', 'SPFH_max', 'TMP_max', 'WIND_max', 'elevation', 'sm_profile', 'sm_profile_wetness', 'sm_rootzone', 'sm_rootzone_wetness', 'sm_surface', 'sm_surface_wetness', 'year', 'month', 'day', 'longitude', 'latitude']\n",
      "DEBUG X_train columns: Index(['EVT', 'EVH', 'NDVI', 'PRES_max', 'SPFH_max', 'TMP_max', 'WIND_max',\n",
      "       'elevation', 'sm_profile', 'sm_profile_wetness', 'sm_rootzone',\n",
      "       'sm_rootzone_wetness', 'sm_surface', 'sm_surface_wetness', 'year',\n",
      "       'month', 'day', 'longitude', 'latitude'],\n",
      "      dtype='object')\n",
      "DEBUG X_train[cat_cols] dtype: int64\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "linear(): input and weight.T shapes cannot be multiplied (64x18 and 6x32)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m x_cont = x_cont.to(device)\n\u001b[32m     20\u001b[39m y_true = y_true.to(device)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_cont\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m probs = torch.sigmoid(logits)\n\u001b[32m     23\u001b[39m preds = (probs > \u001b[32m0.3\u001b[39m).long()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mSAINT.forward\u001b[39m\u001b[34m(self, x_cat, x_cont)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, emb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.embeddings):\n\u001b[32m     34\u001b[39m     tokens.append(emb(x_cat[:, i]))\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m tokens.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcont_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_cont\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     36\u001b[39m tokens = torch.stack(tokens, dim=\u001b[32m1\u001b[39m)\n\u001b[32m     37\u001b[39m attn_output = \u001b[38;5;28mself\u001b[39m.transformer(tokens)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: linear(): input and weight.T shapes cannot be multiplied (64x18 and 6x32)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Make sure your DataModule is set up\n",
    "dm.setup()\n",
    "val_loader = dm.val_dataloader()\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_cat, x_cont, y_true in val_loader:\n",
    "        x_cat = x_cat.to(device)\n",
    "        x_cont = x_cont.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        logits = model(x_cat, x_cont)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs > 0.3).long()\n",
    "        all_preds.extend(preds.cpu().detach().tolist())\n",
    "        all_labels.extend(y_true.cpu().detach().tolist())\n",
    "\n",
    "all_preds = np.array(all_preds).flatten()\n",
    "all_labels = np.array(all_labels).flatten()\n",
    "\n",
    "# Now you can compute metrics as before\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "f1 = f1_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds)\n",
    "recall = recall_score(all_labels, all_preds)\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a16993",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Model Evaluation Analysis\n",
    "1. Accuracy\n",
    "Value: 0.9974\n",
    "Interpretation:\n",
    "The model correctly classified 99.74% of the validation samples. While this appears excellent, accuracy can be misleading in imbalanced datasets (where one class is much more frequent than the other).\n",
    "2. F1 Score\n",
    "Value: 0.5698\n",
    "Interpretation:\n",
    "The F1 score is the harmonic mean of precision and recall. A value of 0.57 indicates a moderate balance between precision and recall, but is much lower than the accuracy, suggesting issues with class imbalance or difficulty in detecting the minority class.\n",
    "3. Precision\n",
    "Value: 0.6571\n",
    "Interpretation:\n",
    "Of all the samples the model predicted as positive (class 1), 65.71% were actually positive. This means that about one-third of positive predictions are false positives.\n",
    "4. Recall\n",
    "Value: 0.5030\n",
    "Interpretation:\n",
    "The model only identified 50.30% of the actual positive cases. This means it is missing nearly half of the true positives (i.e., high false negative rate).\n",
    "5. Confusion Matrix\n",
    "CopyInsert\n",
    "[[145565    132]\n",
    " [   250    253]]\n",
    "Rows: True classes ([0, 1])\n",
    "Columns: Predicted classes ([0, 1])\n",
    "Breakdown:\n",
    "True Negatives (TN): 145,565 (correctly predicted class 0)\n",
    "False Positives (FP): 132 (predicted 1, actually 0)\n",
    "False Negatives (FN): 250 (predicted 0, actually 1)\n",
    "True Positives (TP): 253 (correctly predicted class 1)\n",
    "6. Class Imbalance\n",
    "The dataset is highly imbalanced:\n",
    "Majority class (0): 145,697 samples\n",
    "Minority class (1): 503 samples\n",
    "This imbalance explains the high accuracy (dominated by correct negatives) and the much lower F1, precision, and recall.\n",
    "7. Threshold Setting\n",
    "You used a sigmoid threshold of 0.3 (not the default 0.5). Lowering the threshold increases recall but may reduce precision. Here, recall is still low, so you may want to try even lower thresholds or other balancing techniques.\n",
    "8. Recommendations\n",
    "Metric Focus: Use F1, precision, and recall as your main metrics (not accuracy) due to class imbalance.\n",
    "Threshold Tuning: Experiment with different thresholds to find a better balance between precision and recall.\n",
    "Class Imbalance Handling: Try oversampling/undersampling, class weighting, or synthetic data (e.g., SMOTE) to improve minority class detection.\n",
    "Model Improvements: Consider more complex models, feature engineering, or ensemble methods if appropriate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
